{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parmeters\n",
    "batch, height, width, feature = 2, 3, 3, 2\n",
    "test_landmarks = 2*2\n",
    "test_style_images_num = 5\n",
    "test_style_n_best = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_landmarks(x_landmarks, style_landmarks, style_images, style_images_num=60, style_n_best=16, batch=batch, landmarks_num=68*2):\n",
    "    \"\"\"\n",
    "    param x_landmarks: 트레이닝 이미지의 랜드마크, shape: (batch, 68*2)\n",
    "    param style_landmarks: 스타일 이미지들(Y)의 랜드마크, shape: (60, 68*2)\n",
    "    param style_images: 스타일 이미지들(Y), shape: (60, height, width, 3)\n",
    "    return style_best: batch 당 customized set of style images, shape: (batch, style_n_best, height, width, 3)\n",
    "    ps) style_images_num: 논문에서 Y는 60개의 스타일 이미지의 집합, style_n_best: 16개만 쓰는게 좋다고 한다.\n",
    "    \"\"\"\n",
    "    x_tile = tf.tile(x_landmarks, [1, style_images_num])\n",
    "    x_tile = tf.reshape(x_tile, [batch, style_images_num, landmarks_num])\n",
    "    \n",
    "    style_tile = tf.tile(style_landmarks, [batch, 1])\n",
    "    style_tile = tf.reshape(style_tile, [batch, style_images_num, landmarks_num])\n",
    "    \n",
    "    mse = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(x_tile, style_tile)), 2))\n",
    "    mse = tf.negative(mse) # 작은 값을 가져와야 하니깐!\n",
    "    sort = tf.nn.top_k(mse, style_n_best)\n",
    "    \n",
    "    style_best = tf.gather(style_images, sort.indices)\n",
    "    return style_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_style_loss(vgg_generated_images, vgg_style_best, style_n_best=16, batch=batch):\n",
    "    print(vgg_generated_images.shape)\n",
    "    print(vgg_style_best.shape)\n",
    "    vgg_generated_images_tile = tf.tile(vgg_generated_images, [1, style_n_best, 1, 1])\n",
    "    vgg_generated_images_tile = tf.reshape(vgg_generated_images_tile, [batch, style_n_best, height, width, feature])\n",
    "    \n",
    "    normalize_g = tf.nn.l2_normalize(vgg_generated_images_tile, 4)\n",
    "    normalize_s = tf.nn.l2_normalize(vgg_style_best, 4)\n",
    "\n",
    "    cos_distance = tf.squeeze((1 - tf.reduce_sum(tf.multiply(normalize_g, normalize_s), 4)))\n",
    "    cos_distance = tf.reduce_min(cos_distance, 1)\n",
    "    style_loss = tf.reduce_mean(cos_distance)\n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3, 2)\n",
      "(2, 3, 3, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    x_landmarks = tf.placeholder(tf.float32, shape=(batch, test_landmarks))\n",
    "    style_landmarks = tf.placeholder(tf.float32, shape=(test_style_images_num, test_landmarks))\n",
    "    style_images = tf.placeholder(tf.float32, shape=(test_style_images_num, height, width, feature))\n",
    "    \n",
    "    init_x_landmarks = np.array(\n",
    "        [\n",
    "            [1,2,3,4],\n",
    "            [9,8,7,6]\n",
    "        ])\n",
    "    \n",
    "    init_style_landmarks = np.array(\n",
    "        [\n",
    "            [11, 12, 13, 14],\n",
    "            [21, 22, 23, 24],\n",
    "            [31, 32, 33, 34],\n",
    "            [41, 42, 43, 44],\n",
    "            [51, 52, 53, 54]\n",
    "        ])\n",
    "    \n",
    "    init_style_images = np.array(\n",
    "        [\n",
    "            [[[201, 201], [202, 202], [203, 203]], [[204, 204], [205, 205], [206, 206]], [[207, 207], [208, 208], [209, 209]]],\n",
    "            [[[301, 301], [302, 302], [303, 303]], [[304, 304], [305, 305], [306, 306]], [[307, 307], [308, 308], [309, 309]]],\n",
    "            [[[401, 401], [402, 402], [403, 403]], [[404, 404], [405, 405], [406, 406]], [[407, 407], [408, 408], [409, 409]]],\n",
    "            [[[501, 501], [502, 502], [503, 503]], [[504, 504], [505, 505], [506, 506]], [[507, 507], [508, 508], [509, 509]]],\n",
    "            [[[601, 601], [602, 602], [603, 603]], [[604, 604], [605, 605], [606, 606]], [[607, 607], [608, 608], [609, 609]]]\n",
    "        ])\n",
    "            \n",
    "    style_best = filter_by_landmarks(x_landmarks, style_landmarks, style_images, style_images_num=test_style_images_num, style_n_best=test_style_n_best, batch=batch, landmarks_num=test_landmarks)\n",
    "    \n",
    "    # vgg phase\n",
    "    # vgg_generated_images = vgg(generated_images) \n",
    "    # vgg_style_best = vgg(style_best)\n",
    "    vgg_style_best = style_best\n",
    "    \n",
    "    vgg_generated_images = tf.placeholder(tf.float32, shape=(batch, height, width, feature))\n",
    "    \n",
    "    init_vgg_generated_images = np.array(\n",
    "        [\n",
    "            [[[5, 113], [2, 2], [3, 3]], [[4, 4], [5, 5], [6, 6]], [[7, 7], [8, 8], [9, 9]]],\n",
    "            [[[11, 11], [12, 12], [13, 13]], [[14, 14], [15, 15], [16, 16]], [[17, 17], [18, 18], [19, 19]]]\n",
    "        ])\n",
    "    \n",
    "    style_loss = compute_style_loss(vgg_generated_images, vgg_style_best, test_style_n_best)\n",
    "    \n",
    "    feed_dict = {\n",
    "        x_landmarks: init_x_landmarks,\n",
    "        style_landmarks: init_style_landmarks,\n",
    "        style_images: init_style_images,\n",
    "        vgg_generated_images: init_vgg_generated_images\n",
    "    }\n",
    "\n",
    "    out = sess.run([style_loss], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014573809]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[[ 201.,  201.],\n",
       "           [ 202.,  202.],\n",
       "           [ 203.,  203.]],\n",
       "\n",
       "          [[ 204.,  204.],\n",
       "           [ 205.,  205.],\n",
       "           [ 206.,  206.]],\n",
       "\n",
       "          [[ 207.,  207.],\n",
       "           [ 208.,  208.],\n",
       "           [ 209.,  209.]]],\n",
       "\n",
       "\n",
       "         [[[ 301.,  301.],\n",
       "           [ 302.,  302.],\n",
       "           [ 303.,  303.]],\n",
       "\n",
       "          [[ 304.,  304.],\n",
       "           [ 305.,  305.],\n",
       "           [ 306.,  306.]],\n",
       "\n",
       "          [[ 307.,  307.],\n",
       "           [ 308.,  308.],\n",
       "           [ 309.,  309.]]],\n",
       "\n",
       "\n",
       "         [[[ 401.,  401.],\n",
       "           [ 402.,  402.],\n",
       "           [ 403.,  403.]],\n",
       "\n",
       "          [[ 404.,  404.],\n",
       "           [ 405.,  405.],\n",
       "           [ 406.,  406.]],\n",
       "\n",
       "          [[ 407.,  407.],\n",
       "           [ 408.,  408.],\n",
       "           [ 409.,  409.]]],\n",
       "\n",
       "\n",
       "         [[[ 501.,  501.],\n",
       "           [ 502.,  502.],\n",
       "           [ 503.,  503.]],\n",
       "\n",
       "          [[ 504.,  504.],\n",
       "           [ 505.,  505.],\n",
       "           [ 506.,  506.]],\n",
       "\n",
       "          [[ 507.,  507.],\n",
       "           [ 508.,  508.],\n",
       "           [ 509.,  509.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 201.,  201.],\n",
       "           [ 202.,  202.],\n",
       "           [ 203.,  203.]],\n",
       "\n",
       "          [[ 204.,  204.],\n",
       "           [ 205.,  205.],\n",
       "           [ 206.,  206.]],\n",
       "\n",
       "          [[ 207.,  207.],\n",
       "           [ 208.,  208.],\n",
       "           [ 209.,  209.]]],\n",
       "\n",
       "\n",
       "         [[[ 301.,  301.],\n",
       "           [ 302.,  302.],\n",
       "           [ 303.,  303.]],\n",
       "\n",
       "          [[ 304.,  304.],\n",
       "           [ 305.,  305.],\n",
       "           [ 306.,  306.]],\n",
       "\n",
       "          [[ 307.,  307.],\n",
       "           [ 308.,  308.],\n",
       "           [ 309.,  309.]]],\n",
       "\n",
       "\n",
       "         [[[ 401.,  401.],\n",
       "           [ 402.,  402.],\n",
       "           [ 403.,  403.]],\n",
       "\n",
       "          [[ 404.,  404.],\n",
       "           [ 405.,  405.],\n",
       "           [ 406.,  406.]],\n",
       "\n",
       "          [[ 407.,  407.],\n",
       "           [ 408.,  408.],\n",
       "           [ 409.,  409.]]],\n",
       "\n",
       "\n",
       "         [[[ 501.,  501.],\n",
       "           [ 502.,  502.],\n",
       "           [ 503.,  503.]],\n",
       "\n",
       "          [[ 504.,  504.],\n",
       "           [ 505.,  505.],\n",
       "           [ 506.,  506.]],\n",
       "\n",
       "          [[ 507.,  507.],\n",
       "           [ 508.,  508.],\n",
       "           [ 509.,  509.]]]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
