{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg19\n",
    "from tensorflow_vgg import utils\n",
    "\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.ion() # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parmeters\n",
    "batch, height, width, channel = 2, 3, 3, 3\n",
    "test_landmarks = 2*2\n",
    "test_style_images_num = 5\n",
    "test_style_n_best = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Desktop/FastFaceSwapStyleLoss/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # set vgg => will be normalized?\n",
    "    vgg = vgg19.Vgg19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_by_landmarks(x_landmarks, style_landmarks, style_images, style_images_num=60, style_n_best=16, batch=batch, landmarks_num=68*2):\n",
    "    \"\"\"\n",
    "    param x_landmarks: 트레이닝 이미지의 랜드마크, shape: (batch, 68*2)\n",
    "    param style_landmarks: 스타일 이미지들(Y)의 랜드마크, shape: (60, 68*2)\n",
    "    param style_images: 스타일 이미지들(Y), shape: (60, height, width, 3)\n",
    "    return style_best: batch 당 customized set of style images, shape: (batch, style_n_best, height, width, 3)\n",
    "    ps) style_images_num: 논문에서 Y는 60개의 스타일 이미지의 집합, style_n_best: 16개만 쓰는게 좋다고 한다.\n",
    "    \"\"\"\n",
    "    x_tile = tf.tile(x_landmarks, [1, style_images_num])\n",
    "    x_tile = tf.reshape(x_tile, [batch, style_images_num, landmarks_num])\n",
    "    \n",
    "    style_tile = tf.tile(style_landmarks, [batch, 1])\n",
    "    style_tile = tf.reshape(style_tile, [batch, style_images_num, landmarks_num])\n",
    "    \n",
    "    mse = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(x_tile, style_tile)), 2))\n",
    "    mse = tf.negative(mse) # 작은 값을 가져와야 하니깐!\n",
    "    sort = tf.nn.top_k(mse, style_n_best)\n",
    "    \n",
    "    style_best = tf.gather(style_images, sort.indices)\n",
    "    return style_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_style_loss(vgg_generated_images, vgg_style_best, style_n_best=16, batch=batch):\n",
    "    \"\"\"\n",
    "    param vgg_generated_images: 생성된 이미지를 vgg를 통과시켜 넣은 것, shape: (2, 1, 1, 256)\n",
    "    param vgg_style_best: 각 인풋 이미지에 대해 골라진 베스트 style image들을 vgg를 통과시킨 것, shape: (2, 3, 1, 1, 256)\n",
    "    \"\"\"\n",
    "\n",
    "    _batch, _height, _width, _feature = vgg_generated_images.get_shape().as_list()\n",
    "    vgg_generated_images_tile = tf.tile(vgg_generated_images, [1, style_n_best, 1, 1]) # (2, 3, 1, 256)\n",
    "    \n",
    "    vgg_generated_images_tile = tf.reshape(vgg_generated_images_tile, [batch, style_n_best, _height, _width, _feature])\n",
    "    \n",
    "    normalize_g = tf.nn.l2_normalize(vgg_generated_images_tile, 4)\n",
    "    normalize_s = tf.nn.l2_normalize(vgg_style_best, 4)\n",
    "\n",
    "    cos_distance = tf.squeeze((1 - tf.reduce_sum(tf.multiply(normalize_g, normalize_s), 4)))\n",
    "    cos_distance = tf.reduce_min(cos_distance, 1)\n",
    "    style_loss = tf.reduce_mean(cos_distance)\n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model started\n",
      "build model finished: 0s\n",
      "build model started\n",
      "build model finished: 0s\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    x_landmarks = tf.placeholder(tf.float32, shape=(batch, test_landmarks))\n",
    "    style_landmarks = tf.placeholder(tf.float32, shape=(test_style_images_num, test_landmarks))\n",
    "    style_images = tf.placeholder(tf.float32, shape=(test_style_images_num, height, width, channel))\n",
    "    \n",
    "    init_x_landmarks = np.array(\n",
    "        [\n",
    "            [1,2,3,4],\n",
    "            [9,8,7,6]\n",
    "        ])\n",
    "    \n",
    "    init_style_landmarks = np.array(\n",
    "        [\n",
    "            [11, 12, 13, 14],\n",
    "            [21, 22, 23, 24],\n",
    "            [31, 32, 33, 34],\n",
    "            [41, 42, 43, 44],\n",
    "            [51, 52, 53, 54]\n",
    "        ])\n",
    "    \n",
    "    init_style_images = np.array(\n",
    "        [\n",
    "            [[[201, 201, 201], [202, 202, 201], [203, 203, 201]], [[204, 204, 201], [205, 205, 201], [206, 206, 201]], [[207, 207, 201], [208, 208, 201], [209, 209, 201]]],\n",
    "            [[[301, 301, 201], [302, 302, 201], [303, 303, 201]], [[304, 304, 201], [305, 305, 201], [306, 306, 201]], [[307, 307, 201], [308, 308, 201], [309, 309, 201]]],\n",
    "            [[[401, 401, 201], [402, 402, 201], [403, 403, 201]], [[404, 404, 201], [405, 405, 201], [406, 406, 201]], [[407, 407, 201], [408, 408, 201], [409, 409, 201]]],\n",
    "            [[[501, 501, 201], [502, 502, 201], [503, 503, 201]], [[504, 504, 201], [505, 505, 201], [506, 506, 201]], [[507, 507, 201], [508, 508, 201], [509, 509, 201]]],\n",
    "            [[[601, 601, 201], [602, 602, 201], [603, 603, 201]], [[604, 604, 201], [605, 605, 201], [606, 606, 201]], [[607, 607, 201], [608, 608, 201], [609, 609, 201]]]\n",
    "        ])\n",
    "            \n",
    "    style_best = filter_by_landmarks(x_landmarks, style_landmarks, style_images, style_images_num=test_style_images_num, style_n_best=test_style_n_best, batch=batch, landmarks_num=test_landmarks)\n",
    "\n",
    "    generated_images = tf.placeholder(tf.float32, shape=(batch, height, width, channel))\n",
    "\n",
    "    init_generated_images = np.array(\n",
    "        [\n",
    "            [[[5, 113, 199], [2, 2, 199], [3, 3, 199]], [[4, 4, 199], [5, 5, 199], [6, 6, 199]], [[7, 7, 199], [8, 8, 199], [9, 9, 199]]],\n",
    "            [[[11, 11, 199], [12, 12, 199], [13, 13, 199]], [[14, 14, 199], [15, 15, 199], [16, 16, 199]], [[17, 17, 199], [18, 18, 199], [19, 19, 199]]]\n",
    "        ])\n",
    "    \n",
    "    # vgg phase\n",
    "    vgg.build(generated_images)\n",
    "    relu3_1_generated_image = vgg.conv3_1 # (1, 40, 40, 256)\n",
    "    relu4_1_generated_images = vgg.conv4_1\n",
    "\n",
    "    relu3_1_vgg_style_best = []\n",
    "    relu4_1_vgg_style_best = []\n",
    "    for style_layer_per_batch in tf.unstack(style_best):\n",
    "        vgg.build(style_layer_per_batch)\n",
    "        relu3_1_vgg_style_best.append(vgg.conv3_1)\n",
    "        relu4_1_vgg_style_best.append(vgg.conv4_1)\n",
    "    \n",
    "    relu3_1_vgg_style_best = tf.stack(relu3_1_vgg_style_best)\n",
    "    relu4_1_vgg_style_best = tf.stack(relu4_1_vgg_style_best)\n",
    "        \n",
    "    relu3_1_style_loss = compute_style_loss(relu3_1_generated_image, relu3_1_vgg_style_best, style_n_best=test_style_n_best)\n",
    "    relu4_1_style_loss = compute_style_loss(relu4_1_generated_images, relu4_1_vgg_style_best, style_n_best=test_style_n_best)\n",
    "    style_loss = relu3_1_style_loss + relu4_1_style_loss\n",
    "    \n",
    "    feed_dict = {\n",
    "        x_landmarks: init_x_landmarks,\n",
    "        style_landmarks: init_style_landmarks,\n",
    "        style_images: init_style_images,\n",
    "        generated_images: init_generated_images\n",
    "    }\n",
    "\n",
    "    out = sess.run([style_loss], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017204434]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
