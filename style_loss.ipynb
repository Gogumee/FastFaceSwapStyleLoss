{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg19\n",
    "from tensorflow_vgg import utils\n",
    "\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.ion() # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_local_patches(layer, patch_size=1, padding='VALID'):\n",
    "    return tf.extract_image_patches(layer, ksizes=[1, patch_size, patch_size, 1],\n",
    "                                    strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_images_by_landmarks(input_image, style_images, input_image_landmark=None, style_images_landmarks=None, n_best=16):\n",
    "    \"\"\"\n",
    "    input_image_landmarks := landmarks of a training image (1 image)\n",
    "    style_images_landmarks := landmarks of style images (60 images)\n",
    "    \"\"\"\n",
    "    eucidean_distances = map_fn(lambda x: tf.losses.mean_squared_error(x, input_image_landmark)  )\n",
    "    \n",
    "    elems = np.array([1, 2, 3, 4, 5, 6])\n",
    "    squares = map_fn(lambda x: x * x, elems, dtype=tf.float32)\n",
    "    # squares == [1, 4, 9, 16, 25, 36]\n",
    "    \n",
    "    \n",
    "    return style_images[:n_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Desktop/FastFaceSwapStyleLoss/tensorflow_vgg/vgg19.npy\n",
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # set vgg => will be normalized?\n",
    "    vgg = vgg19.Vgg19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# set style image feed\n",
    "style_images = []\n",
    "for style_image_filename in os.listdir(\"style_data\")[1:]:\n",
    "    style_images.append(io.imread('./style_data/' + style_image_filename))\n",
    "style_images_init = np.asarray(style_images)\n",
    "print(style_images_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model started\n",
      "build model finished: 0s\n",
      "build model started\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    with sess.as_default():\n",
    "        # input\n",
    "        batch, height, width, channel = None, 160, 160, 3\n",
    "        style_images_num = 60\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, [batch, height, width, channel])\n",
    "        fake_generated_image = tf.placeholder(tf.float32, [1, height, width, channel])\n",
    "        style_images = tf.placeholder(tf.float32, [style_images_num, height, width, channel])\n",
    "        sorted_style_images = sort_images_by_landmarks(x, style_images) # (16, 160, 160, 3)\n",
    "\n",
    "        x_init = np.expand_dims(io.imread('./data/61192.jpg'), axis=0)\n",
    "        fake_generated_image_init = np.expand_dims(io.imread('./data/61284.jpg'), axis=0)\n",
    "        feed_dict = {\n",
    "            x: x_init, \n",
    "            fake_generated_image: fake_generated_image_init,\n",
    "            style_images: style_images_init,\n",
    "        }\n",
    "\n",
    "        vgg.build(fake_generated_image)\n",
    "        relu3_1_fake_generated_image = vgg.conv3_1 # (1, 40, 40, 256)\n",
    "        relu4_1_fake_generated_image = vgg.conv4_1\n",
    "        \n",
    "        vgg.build(sorted_style_images)\n",
    "        relu3_1_sorted_style_images = vgg.conv3_1 # (16, 40, 40, 256)\n",
    "        relu4_1_sorted_style_images = vgg.conv4_1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # just relu3_1\n",
    "        fake_generated_layer_patches = create_local_patches(relu3_1_fake_generated_image)\n",
    "        style_images_layer_patches = create_local_patches(relu3_1_sorted_style_images)\n",
    "        \n",
    "        g_patches, s_patches = sess.run(\n",
    "            [fake_generated_layer_patches, style_images_layer_patches],\n",
    "            feed_dict=feed_dict)\n",
    "        \n",
    "#         _relu3_1_fake_generated_image, _sorted_style_images = sess.run(\n",
    "#             [relu3_1_fake_generated_image, relu3_1_sorted_style_images], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 40, 256)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 40, 40, 256)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125828.0078125 ,    4749.07617188,       0.        , ...,\n",
       "             0.        ,   34419.46484375,   18869.73242188], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_patches.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_2:0' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:1' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:2' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:3' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:4' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:5' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:6' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:7' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:8' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:9' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:10' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:11' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:12' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:13' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:14' shape=(40, 40, 256) dtype=float32>,\n",
       " <tf.Tensor 'unstack_2:15' shape=(40, 40, 256) dtype=float32>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unstack(style_images_layer_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patch_matching(generated_layer_patches, style_layers_patches, patch_size=1):\n",
    "    for style_layer_patches in style_layers_patches:\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrf_loss(style_layers, generated_layer, patch_size=1, name=''):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
